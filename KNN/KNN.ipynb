{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import struct\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "import time\n",
    "import CQNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 卷积神经网络模型\n",
    "class ConvNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvNet, self).__init__()\n",
    "\n",
    "        # 编码器部分\n",
    "        self.encoder1 = nn.Sequential(\n",
    "            nn.Conv2d(1, 16, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "        )\n",
    "\n",
    "        self.encoder2 = nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                1, 16, kernel_size=5, stride=1, padding=2\n",
    "            ),  # 使用不同的卷积核大小\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "        )\n",
    "\n",
    "        self.encoder3 = nn.Sequential(\n",
    "            nn.Conv2d(1, 16, kernel_size=7, stride=1, padding=3),  # 再增加一个并行层\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "        )\n",
    "\n",
    "        self.encoder4 = nn.Sequential(\n",
    "            nn.Conv2d(1, 16, kernel_size=9, stride=1, padding=4),  # 继续增加\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "        )\n",
    "\n",
    "        self.encoder5 = nn.Sequential(\n",
    "            nn.Conv2d(1, 16, kernel_size=11, stride=1, padding=5),  # 再增加一个\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "        )\n",
    "\n",
    "        self.encoder6 = nn.Sequential(\n",
    "            nn.Conv2d(1, 16, kernel_size=13, stride=1, padding=6),  # 最后一个并行层\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "        )\n",
    "\n",
    "        self.encoder3_combined = nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                16 * 6, 32, kernel_size=3, stride=1, padding=1\n",
    "            ),  # 更新为输入通道数为并行输出的总和\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "        )\n",
    "\n",
    "        # 解码器部分\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.ConvTranspose2d(32, 16, kernel_size=2, stride=2),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(16, 1, kernel_size=2, stride=2),\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # 并行编码\n",
    "        encoded1 = self.encoder1(x)\n",
    "        encoded2 = self.encoder2(x)\n",
    "        encoded3 = self.encoder3(x)\n",
    "        encoded4 = self.encoder4(x)\n",
    "        encoded5 = self.encoder5(x)\n",
    "        encoded6 = self.encoder6(x)\n",
    "\n",
    "        # 将所有编码器的输出拼接在一起\n",
    "        encoded = torch.cat(\n",
    "            (encoded1, encoded2, encoded3, encoded4, encoded5, encoded6), dim=1\n",
    "        )  # 在通道维度拼接\n",
    "\n",
    "        # 继续编码\n",
    "        encoded = self.encoder3_combined(encoded)\n",
    "\n",
    "        # 解码过程\n",
    "        decoded = self.decoder(encoded)\n",
    "        return decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 一层并行\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "# 卷积神经网络模型\n",
    "class ConvNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvNet, self).__init__()\n",
    "        # 编码器部分\n",
    "        self.encoder1 = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            nn.Conv2d(32, 128, kernel_size=5, stride=1, padding=2),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "        )\n",
    "\n",
    "        self.encoder2 = nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                1, 32, kernel_size=15, stride=1, padding=7\n",
    "            ),  # 使用不同的卷积核大小\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            nn.Conv2d(\n",
    "                32, 64, kernel_size=3, stride=1, padding=1\n",
    "            ),  # 使用不同的卷积核大小\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "        )\n",
    "\n",
    "        # self.encoder3 = nn.Sequential(\n",
    "        #     nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1),\n",
    "        #     nn.ReLU(),\n",
    "        #     nn.MaxPool2d(2, 2)\n",
    "        # )\n",
    "\n",
    "        # 解码器部分\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.ConvTranspose2d(192, 64, kernel_size=2, stride=2),\n",
    "            nn.ReLU(),\n",
    "            # nn.ConvTranspose2d(32, 16, kernel_size=2, stride=2),\n",
    "            # nn.ReLU(),\n",
    "            nn.ConvTranspose2d(64, 1, kernel_size=2, stride=2),\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # 并行编码\n",
    "        encoded1 = self.encoder1(x)\n",
    "        encoded2 = self.encoder2(x)\n",
    "\n",
    "        # 将两个编码器的输出拼接在一起\n",
    "        encoded = torch.cat((encoded1, encoded2), dim=1)  # 在通道维度拼接\n",
    "\n",
    "        # 继续编码\n",
    "        # encoded = self.encoder3(encoded)\n",
    "\n",
    "        # 解码过程\n",
    "        decoded = self.decoder(encoded)\n",
    "        return decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 一层并行 & dropout\n",
    "class ConvNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvNet, self).__init__()\n",
    "        # 编码器部分\n",
    "        self.encoder1 = nn.Sequential(\n",
    "            nn.Conv2d(1, 16, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            nn.Conv2d(16, 32, kernel_size=5, stride=1, padding=2),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            # nn.Dropout(0.25)  # 加入Dropout层，丢弃率为25%\n",
    "        )\n",
    "\n",
    "        self.encoder2 = nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                1, 16, kernel_size=15, stride=1, padding=7\n",
    "            ),  # 使用不同的卷积核大小\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            nn.Conv2d(16, 32, kernel_size=5, stride=1, padding=2),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            # nn.Dropout(0.25)  # 加入Dropout层，丢弃率为25%\n",
    "        )\n",
    "\n",
    "        self.encoder3 = nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                1, 16, kernel_size=3, stride=1, padding=1\n",
    "            ),  # 使用不同的卷积核大小\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(4, 4),\n",
    "        )\n",
    "\n",
    "        self.encoder4 = nn.Sequential(\n",
    "            nn.Conv2d(80, 80, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            # nn.Dropout(0.25)  # 加入Dropout层\n",
    "        )\n",
    "\n",
    "        # 解码器部分\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.ConvTranspose2d(80, 32, kernel_size=2, stride=2),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(32, 16, kernel_size=2, stride=2),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(16, 1, kernel_size=2, stride=2),\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # 并行编码\n",
    "        encoded1 = self.encoder1(x)\n",
    "        encoded2 = self.encoder2(x)\n",
    "        encoded3 = self.encoder3(x)\n",
    "\n",
    "        # 将两个编码器的输出拼接在一起\n",
    "        encoded = torch.cat((encoded1, encoded2, encoded3), dim=1)  # 在通道维度拼接\n",
    "\n",
    "        # 继续编码\n",
    "        encoded = self.encoder4(encoded)\n",
    "\n",
    "        # 解码过程\n",
    "        decoded = self.decoder(encoded)\n",
    "        return decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 深度卷积神经网络模型\n",
    "class DeepConvNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DeepConvNet, self).__init__()\n",
    "        # 编码器部分\n",
    "        self.encoder1 = nn.Sequential(\n",
    "            nn.Conv2d(1, 64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "        )\n",
    "\n",
    "        self.encoder2 = nn.Sequential(\n",
    "            nn.Conv2d(1, 64, kernel_size=7, stride=1, padding=3),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "        )\n",
    "\n",
    "        # 新增一个更深的编码器分支\n",
    "        self.encoder3 = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, kernel_size=15, stride=1, padding=7),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            nn.Conv2d(32, 64, kernel_size=5, stride=1, padding=2),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "        )\n",
    "                # 新增一个更深的编码器分支\n",
    "        self.encoder4 = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, kernel_size=25, stride=1, padding=12),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            nn.Conv2d(32, 64, kernel_size=7, stride=1, padding=3),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "        )\n",
    "\n",
    "        # 解码器部分\n",
    "        # 解码器部分，调整卷积转置层的参数来减少输出尺寸\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.ConvTranspose2d(384, 128, kernel_size=2, stride=2),  # 将通道从 384 减少到 128\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ConvTranspose2d(128, 1, kernel_size=2, stride=2),  # 减少通道数，增加空间分辨率\n",
    "            # nn.ReLU(),\n",
    "            # nn.BatchNorm2d(64),\n",
    "            # nn.ConvTranspose2d(64, 1, kernel_size=4, stride=2, padding=1),  # 减少输出到目标大小\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        # 并行编码\n",
    "        encoded1 = self.encoder1(x)\n",
    "        encoded2 = self.encoder2(x)\n",
    "        encoded3 = self.encoder3(x)\n",
    "        encoded4 = self.encoder4(x)\n",
    "\n",
    "        # 将三个编码器的输出拼接在一起\n",
    "        encoded = torch.cat((encoded1, encoded2, encoded3, encoded4), dim=1)  # 在通道维度拼接\n",
    "\n",
    "        # 解码过程\n",
    "        decoded = self.decoder(encoded)\n",
    "        return decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# origin model\n",
    "class ConvNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvNet, self).__init__()\n",
    "        # 编码器部分\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(1, 16, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            nn.Conv2d(16, 32, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "        )\n",
    "\n",
    "        # 解码器部分\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.ConvTranspose2d(32, 16, kernel_size=2, stride=2),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(16, 1, kernel_size=2, stride=2),\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        encoded = self.encoder(x)\n",
    "        decoded = self.decoder(encoded)\n",
    "        return decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([200, 1, 600, 512])\n"
     ]
    }
   ],
   "source": [
    "train_num = 40\n",
    "# Read and reshape image data\n",
    "\n",
    "file_path = \"./data/go22-26m.dat\"\n",
    "\n",
    "img_8bit_matrix = CQNet.read_sonar_data(file_path, train_num)\n",
    "\n",
    "ans = CQNet.reshape_img_matrix(img_8bit_matrix, train_num)  # ans为最后读出来的三维数组\n",
    "\n",
    "ans_tensor, labels_tensor = CQNet.prepare_data_and_labels(\n",
    "    ans, train_num, show_labels=False, weather_plot=False\n",
    ")\n",
    "# new_ans_tensor, new_labels_tensor = prepare_data_and_labels(ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 初始化卷积网络\n",
    "conv_net = DeepConvNet()\n",
    "# 检查 GPU 是否可用\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# 加载预训练模型的权重\n",
    "conv_net.load_state_dict(torch.load(\"./model/SuperDeep.pth\"))\n",
    "# 将模型移动到 GPU\n",
    "conv_net.to(device)\n",
    "# 将数据和标签移动到 GPU\n",
    "ans_tensor = ans_tensor.to(device)\n",
    "labels_tensor = labels_tensor.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training supervised model...\n",
      "Epoch [1/10], Loss: 0.0458, Time: 306.6237187385559\n",
      "Epoch [2/10], Loss: 0.0278, Time: 338.21366715431213\n",
      "Epoch [3/10], Loss: 0.0204, Time: 331.3296720981598\n",
      "Epoch [4/10], Loss: 0.0183, Time: 354.2693786621094\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# for i in range(20):\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# 开始训练卷积神经网络\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[43mCQNet\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_supervised_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconv_net\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mans_tensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_num\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mlabels_tensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m8\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.01\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# 保存模型参数\u001b[39;00m\n",
      "File \u001b[1;32md:\\DevelopCode\\pytorch\\sonar\\KNN\\CQNet.py:212\u001b[0m, in \u001b[0;36mtrain_supervised_model\u001b[1;34m(model, data, train_num, labels, batch_size, learning_rate)\u001b[0m\n\u001b[0;32m    209\u001b[0m     loss \u001b[38;5;241m=\u001b[39m criterion(output, batch_labels)\n\u001b[0;32m    211\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m--> 212\u001b[0m     \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    213\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m    214\u001b[0m \u001b[38;5;66;03m# 清空缓存显存\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Lenovo\\.conda\\envs\\pytorch\\Lib\\site-packages\\torch\\_tensor.py:522\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    512\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    513\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    514\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    515\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    520\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[0;32m    521\u001b[0m     )\n\u001b[1;32m--> 522\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    523\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[0;32m    524\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Lenovo\\.conda\\envs\\pytorch\\Lib\\site-packages\\torch\\autograd\\__init__.py:259\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    250\u001b[0m inputs \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    251\u001b[0m     (inputs,)\n\u001b[0;32m    252\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(inputs, (torch\u001b[38;5;241m.\u001b[39mTensor, graph\u001b[38;5;241m.\u001b[39mGradientEdge))\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    255\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mtuple\u001b[39m()\n\u001b[0;32m    256\u001b[0m )\n\u001b[0;32m    258\u001b[0m grad_tensors_ \u001b[38;5;241m=\u001b[39m _tensor_or_tensors_to_tuple(grad_tensors, \u001b[38;5;28mlen\u001b[39m(tensors))\n\u001b[1;32m--> 259\u001b[0m grad_tensors_ \u001b[38;5;241m=\u001b[39m \u001b[43m_make_grads\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_grads_batched\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    260\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m retain_graph \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    261\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n",
      "File \u001b[1;32mc:\\Users\\Lenovo\\.conda\\envs\\pytorch\\Lib\\site-packages\\torch\\autograd\\__init__.py:142\u001b[0m, in \u001b[0;36m_make_grads\u001b[1;34m(outputs, grads, is_grads_batched)\u001b[0m\n\u001b[0;32m    136\u001b[0m         msg \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    137\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgrad can be implicitly created only for real scalar outputs\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    138\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mout\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    139\u001b[0m         )\n\u001b[0;32m    140\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(msg)\n\u001b[0;32m    141\u001b[0m     new_grads\u001b[38;5;241m.\u001b[39mappend(\n\u001b[1;32m--> 142\u001b[0m         \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mones_like\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemory_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpreserve_format\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    143\u001b[0m     )\n\u001b[0;32m    144\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    145\u001b[0m     new_grads\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# for i in range(20):\n",
    "# 开始训练卷积神经网络\n",
    "CQNet.train_supervised_model(conv_net, ans_tensor, train_num = 10, labels= labels_tensor, batch_size=8, learning_rate=0.01)\n",
    "# 保存模型参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 保存模型参数\n",
    "torch.save(conv_net.state_dict(), \"./model/SuperDeep.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74afd5a804cb44ec9344b484b53ed864",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=0, description='Slice:', max=19), Output()), _dom_classes=('widget-inter…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 使用训练后的模型进行预测\n",
    "conv_net.eval()\n",
    "with torch.no_grad():\n",
    "    predictions = conv_net(ans_tensor)\n",
    "\n",
    "# 交互式显示切片和预测结果\n",
    "CQNet.interactive_plot(ans_tensor[0:1], predictions[0:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ans_tensor[0:10].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchviz import make_dot\n",
    "\n",
    "# 创建模型实例\n",
    "conv_net = ConvNet()\n",
    "\n",
    "# 生成一个随机输入数据\n",
    "x = torch.randn(1, 1, 1200, 1024)  # 根据您的输入尺寸进行调整\n",
    "\n",
    "# 前向传播\n",
    "y = conv_net(x)\n",
    "\n",
    "# 可视化计算图\n",
    "dot = make_dot(y, params=dict(conv_net.named_parameters()))\n",
    "dot.render(\"conv_net_architecture\", format=\"png\")  # 生成 PNG 文件"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
