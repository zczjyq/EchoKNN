{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import struct\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "import time\n",
    "import CQNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 卷积神经网络模型\n",
    "class ConvNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvNet, self).__init__()\n",
    "\n",
    "        # 编码器部分\n",
    "        self.encoder1 = nn.Sequential(\n",
    "            nn.Conv2d(1, 16, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "        )\n",
    "\n",
    "        self.encoder2 = nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                1, 16, kernel_size=5, stride=1, padding=2\n",
    "            ),  # 使用不同的卷积核大小\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "        )\n",
    "\n",
    "        self.encoder3 = nn.Sequential(\n",
    "            nn.Conv2d(1, 16, kernel_size=7, stride=1, padding=3),  # 再增加一个并行层\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "        )\n",
    "\n",
    "        self.encoder4 = nn.Sequential(\n",
    "            nn.Conv2d(1, 16, kernel_size=9, stride=1, padding=4),  # 继续增加\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "        )\n",
    "\n",
    "        self.encoder5 = nn.Sequential(\n",
    "            nn.Conv2d(1, 16, kernel_size=11, stride=1, padding=5),  # 再增加一个\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "        )\n",
    "\n",
    "        self.encoder6 = nn.Sequential(\n",
    "            nn.Conv2d(1, 16, kernel_size=13, stride=1, padding=6),  # 最后一个并行层\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "        )\n",
    "\n",
    "        self.encoder3_combined = nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                16 * 6, 32, kernel_size=3, stride=1, padding=1\n",
    "            ),  # 更新为输入通道数为并行输出的总和\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "        )\n",
    "\n",
    "        # 解码器部分\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.ConvTranspose2d(32, 16, kernel_size=2, stride=2),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(16, 1, kernel_size=2, stride=2),\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # 并行编码\n",
    "        encoded1 = self.encoder1(x)\n",
    "        encoded2 = self.encoder2(x)\n",
    "        encoded3 = self.encoder3(x)\n",
    "        encoded4 = self.encoder4(x)\n",
    "        encoded5 = self.encoder5(x)\n",
    "        encoded6 = self.encoder6(x)\n",
    "\n",
    "        # 将所有编码器的输出拼接在一起\n",
    "        encoded = torch.cat(\n",
    "            (encoded1, encoded2, encoded3, encoded4, encoded5, encoded6), dim=1\n",
    "        )  # 在通道维度拼接\n",
    "\n",
    "        # 继续编码\n",
    "        encoded = self.encoder3_combined(encoded)\n",
    "\n",
    "        # 解码过程\n",
    "        decoded = self.decoder(encoded)\n",
    "        return decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 一层并行\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "# 卷积神经网络模型\n",
    "class ConvNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvNet, self).__init__()\n",
    "        # 编码器部分\n",
    "        self.encoder1 = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            nn.Conv2d(32, 128, kernel_size=5, stride=1, padding=2),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "        )\n",
    "\n",
    "        self.encoder2 = nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                1, 32, kernel_size=15, stride=1, padding=7\n",
    "            ),  # 使用不同的卷积核大小\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            nn.Conv2d(\n",
    "                32, 64, kernel_size=3, stride=1, padding=1\n",
    "            ),  # 使用不同的卷积核大小\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "        )\n",
    "\n",
    "        # self.encoder3 = nn.Sequential(\n",
    "        #     nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1),\n",
    "        #     nn.ReLU(),\n",
    "        #     nn.MaxPool2d(2, 2)\n",
    "        # )\n",
    "\n",
    "        # 解码器部分\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.ConvTranspose2d(192, 64, kernel_size=2, stride=2),\n",
    "            nn.ReLU(),\n",
    "            # nn.ConvTranspose2d(32, 16, kernel_size=2, stride=2),\n",
    "            # nn.ReLU(),\n",
    "            nn.ConvTranspose2d(64, 1, kernel_size=2, stride=2),\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # 并行编码\n",
    "        encoded1 = self.encoder1(x)\n",
    "        encoded2 = self.encoder2(x)\n",
    "\n",
    "        # 将两个编码器的输出拼接在一起\n",
    "        encoded = torch.cat((encoded1, encoded2), dim=1)  # 在通道维度拼接\n",
    "\n",
    "        # 继续编码\n",
    "        # encoded = self.encoder3(encoded)\n",
    "\n",
    "        # 解码过程\n",
    "        decoded = self.decoder(encoded)\n",
    "        return decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 一层并行 & dropout\n",
    "class ConvNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvNet, self).__init__()\n",
    "        # 编码器部分\n",
    "        self.encoder1 = nn.Sequential(\n",
    "            nn.Conv2d(1, 16, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            nn.Conv2d(16, 32, kernel_size=5, stride=1, padding=2),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            # nn.Dropout(0.25)  # 加入Dropout层，丢弃率为25%\n",
    "        )\n",
    "\n",
    "        self.encoder2 = nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                1, 16, kernel_size=15, stride=1, padding=7\n",
    "            ),  # 使用不同的卷积核大小\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            nn.Conv2d(16, 32, kernel_size=5, stride=1, padding=2),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            # nn.Dropout(0.25)  # 加入Dropout层，丢弃率为25%\n",
    "        )\n",
    "\n",
    "        self.encoder3 = nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                1, 16, kernel_size=3, stride=1, padding=1\n",
    "            ),  # 使用不同的卷积核大小\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(4, 4),\n",
    "        )\n",
    "\n",
    "        self.encoder4 = nn.Sequential(\n",
    "            nn.Conv2d(80, 80, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            # nn.Dropout(0.25)  # 加入Dropout层\n",
    "        )\n",
    "\n",
    "        # 解码器部分\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.ConvTranspose2d(80, 32, kernel_size=2, stride=2),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(32, 16, kernel_size=2, stride=2),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(16, 1, kernel_size=2, stride=2),\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # 并行编码\n",
    "        encoded1 = self.encoder1(x)\n",
    "        encoded2 = self.encoder2(x)\n",
    "        encoded3 = self.encoder3(x)\n",
    "\n",
    "        # 将两个编码器的输出拼接在一起\n",
    "        encoded = torch.cat((encoded1, encoded2, encoded3), dim=1)  # 在通道维度拼接\n",
    "\n",
    "        # 继续编码\n",
    "        encoded = self.encoder4(encoded)\n",
    "\n",
    "        # 解码过程\n",
    "        decoded = self.decoder(encoded)\n",
    "        return decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 深度卷积神经网络模型\n",
    "class DeepConvNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DeepConvNet, self).__init__()\n",
    "        # 编码器部分\n",
    "        self.encoder1 = nn.Sequential(\n",
    "            nn.Conv2d(1, 64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "        )\n",
    "\n",
    "        self.encoder2 = nn.Sequential(\n",
    "            nn.Conv2d(1, 64, kernel_size=7, stride=1, padding=3),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "        )\n",
    "\n",
    "        # 新增一个更深的编码器分支\n",
    "        self.encoder3 = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, kernel_size=15, stride=1, padding=7),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            nn.Conv2d(32, 64, kernel_size=5, stride=1, padding=2),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "        )\n",
    "                # 新增一个更深的编码器分支\n",
    "        self.encoder4 = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, kernel_size=25, stride=1, padding=12),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            nn.Conv2d(32, 64, kernel_size=7, stride=1, padding=3),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "        )\n",
    "\n",
    "        # 解码器部分\n",
    "        # 解码器部分，调整卷积转置层的参数来减少输出尺寸\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.ConvTranspose2d(384, 128, kernel_size=2, stride=2),  # 将通道从 384 减少到 128\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ConvTranspose2d(128, 1, kernel_size=2, stride=2),  # 减少通道数，增加空间分辨率\n",
    "            # nn.ReLU(),\n",
    "            # nn.BatchNorm2d(64),\n",
    "            # nn.ConvTranspose2d(64, 1, kernel_size=4, stride=2, padding=1),  # 减少输出到目标大小\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        # 并行编码\n",
    "        encoded1 = self.encoder1(x)\n",
    "        encoded2 = self.encoder2(x)\n",
    "        encoded3 = self.encoder3(x)\n",
    "        encoded4 = self.encoder4(x)\n",
    "\n",
    "        # 将三个编码器的输出拼接在一起\n",
    "        encoded = torch.cat((encoded1, encoded2, encoded3, encoded4), dim=1)  # 在通道维度拼接\n",
    "\n",
    "        # 解码过程\n",
    "        decoded = self.decoder(encoded)\n",
    "        return decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# origin model\n",
    "class ConvNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvNet, self).__init__()\n",
    "        # 编码器部分\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(1, 16, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            nn.Conv2d(16, 32, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "        )\n",
    "\n",
    "        # 解码器部分\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.ConvTranspose2d(32, 16, kernel_size=2, stride=2),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(16, 1, kernel_size=2, stride=2),\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        encoded = self.encoder(x)\n",
    "        decoded = self.decoder(encoded)\n",
    "        return decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([250, 1, 600, 512])\n"
     ]
    }
   ],
   "source": [
    "train_num = 50\n",
    "# Read and reshape image data\n",
    "\n",
    "file_path = \"./data/go22-26m.dat\"\n",
    "\n",
    "img_8bit_matrix = CQNet.read_sonar_data(file_path, train_num)\n",
    "\n",
    "ans = CQNet.reshape_img_matrix(img_8bit_matrix, train_num)  # ans为最后读出来的三维数组\n",
    "\n",
    "ans_tensor, labels_tensor = CQNet.prepare_data_and_labels(\n",
    "    ans, train_num, show_labels=False, weather_plot=False\n",
    ")\n",
    "# new_ans_tensor, new_labels_tensor = prepare_data_and_labels(ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 初始化卷积网络\n",
    "conv_net = DeepConvNet()\n",
    "# 检查 GPU 是否可用\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# 加载预训练模型的权重\n",
    "conv_net.load_state_dict(torch.load(\"./model/SuperDeep.pth\"))\n",
    "# 将模型移动到 GPU\n",
    "conv_net.to(device)\n",
    "# 将数据和标签移动到 GPU\n",
    "ans_tensor = ans_tensor.to(device)\n",
    "labels_tensor = labels_tensor.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training supervised model...\n",
      "Batch 1/32, Loss: 0.0016\n",
      "Batch 2/32, Loss: 0.0766\n",
      "Batch 3/32, Loss: 0.0062\n",
      "Batch 4/32, Loss: 0.0146\n",
      "Batch 5/32, Loss: 0.0180\n",
      "Batch 6/32, Loss: 0.0121\n",
      "Batch 7/32, Loss: 0.0115\n",
      "Batch 8/32, Loss: 0.0118\n",
      "Batch 9/32, Loss: 0.0098\n",
      "Batch 10/32, Loss: 0.0111\n",
      "Batch 11/32, Loss: 0.0049\n",
      "Batch 12/32, Loss: 0.0060\n",
      "Batch 13/32, Loss: 0.0063\n",
      "Batch 14/32, Loss: 0.0076\n",
      "Batch 15/32, Loss: 0.0059\n",
      "Batch 16/32, Loss: 0.0046\n",
      "Batch 17/32, Loss: 0.0045\n",
      "Batch 18/32, Loss: 0.0034\n",
      "Batch 19/32, Loss: 0.0042\n",
      "Batch 20/32, Loss: 0.0036\n",
      "Batch 21/32, Loss: 0.0045\n",
      "Batch 22/32, Loss: 0.0042\n",
      "Batch 23/32, Loss: 0.0030\n",
      "Batch 24/32, Loss: 0.0043\n",
      "Batch 25/32, Loss: 0.0028\n",
      "Batch 26/32, Loss: 0.0036\n",
      "Batch 27/32, Loss: 0.0025\n",
      "Batch 28/32, Loss: 0.0030\n",
      "Batch 29/32, Loss: 0.0027\n",
      "Batch 30/32, Loss: 0.0024\n",
      "Batch 31/32, Loss: 0.0028\n",
      "Batch 32/32, Loss: 0.0026\n",
      "Epoch [1/6] finished, Total Loss: 0.2627, Time: 378.74 seconds\n",
      "Layer: encoder1.0.weight, Grad Norm: 0.0005\n",
      "Layer: encoder1.0.bias, Grad Norm: 0.0003\n",
      "Layer: encoder1.2.weight, Grad Norm: 0.0001\n",
      "Layer: encoder1.2.bias, Grad Norm: 0.0001\n",
      "Layer: encoder1.4.weight, Grad Norm: 0.0002\n",
      "Layer: encoder1.4.bias, Grad Norm: 0.0000\n",
      "Layer: encoder1.6.weight, Grad Norm: 0.0001\n",
      "Layer: encoder1.6.bias, Grad Norm: 0.0001\n",
      "Layer: encoder2.0.weight, Grad Norm: 0.0010\n",
      "Layer: encoder2.0.bias, Grad Norm: 0.0011\n",
      "Layer: encoder2.2.weight, Grad Norm: 0.0002\n",
      "Layer: encoder2.2.bias, Grad Norm: 0.0001\n",
      "Layer: encoder2.4.weight, Grad Norm: 0.0004\n",
      "Layer: encoder2.4.bias, Grad Norm: 0.0000\n",
      "Layer: encoder2.6.weight, Grad Norm: 0.0002\n",
      "Layer: encoder2.6.bias, Grad Norm: 0.0001\n",
      "Layer: encoder3.0.weight, Grad Norm: 0.0016\n",
      "Layer: encoder3.0.bias, Grad Norm: 0.0006\n",
      "Layer: encoder3.2.weight, Grad Norm: 0.0004\n",
      "Layer: encoder3.2.bias, Grad Norm: 0.0004\n",
      "Layer: encoder3.4.weight, Grad Norm: 0.0010\n",
      "Layer: encoder3.4.bias, Grad Norm: 0.0000\n",
      "Layer: encoder3.6.weight, Grad Norm: 0.0004\n",
      "Layer: encoder3.6.bias, Grad Norm: 0.0001\n",
      "Layer: encoder4.0.weight, Grad Norm: 0.0041\n",
      "Layer: encoder4.0.bias, Grad Norm: 0.0007\n",
      "Layer: encoder4.2.weight, Grad Norm: 0.0005\n",
      "Layer: encoder4.2.bias, Grad Norm: 0.0014\n",
      "Layer: encoder4.4.weight, Grad Norm: 0.0015\n",
      "Layer: encoder4.4.bias, Grad Norm: 0.0000\n",
      "Layer: encoder4.6.weight, Grad Norm: 0.0008\n",
      "Layer: encoder4.6.bias, Grad Norm: 0.0002\n",
      "Layer: decoder.0.weight, Grad Norm: 0.0014\n",
      "Layer: decoder.0.bias, Grad Norm: 0.0000\n",
      "Layer: decoder.2.weight, Grad Norm: 0.0005\n",
      "Layer: decoder.2.bias, Grad Norm: 0.0003\n",
      "Layer: decoder.3.weight, Grad Norm: 0.0009\n",
      "Layer: decoder.3.bias, Grad Norm: 0.0001\n",
      "Batch 1/32, Loss: 0.0031\n",
      "Batch 2/32, Loss: 0.0019\n",
      "Batch 3/32, Loss: 0.0021\n",
      "Batch 4/32, Loss: 0.0026\n",
      "Batch 5/32, Loss: 0.0024\n",
      "Batch 6/32, Loss: 0.0021\n",
      "Batch 7/32, Loss: 0.0019\n",
      "Batch 8/32, Loss: 0.0025\n",
      "Batch 9/32, Loss: 0.0023\n",
      "Batch 10/32, Loss: 0.0020\n",
      "Batch 11/32, Loss: 0.0019\n",
      "Batch 12/32, Loss: 0.0019\n",
      "Batch 13/32, Loss: 0.0018\n",
      "Batch 14/32, Loss: 0.0017\n",
      "Batch 15/32, Loss: 0.0015\n",
      "Batch 16/32, Loss: 0.0017\n",
      "Batch 17/32, Loss: 0.0018\n",
      "Batch 18/32, Loss: 0.0019\n",
      "Batch 19/32, Loss: 0.0018\n",
      "Batch 20/32, Loss: 0.0017\n",
      "Batch 21/32, Loss: 0.0015\n",
      "Batch 22/32, Loss: 0.0014\n",
      "Batch 23/32, Loss: 0.0016\n",
      "Batch 24/32, Loss: 0.0018\n",
      "Batch 25/32, Loss: 0.0015\n",
      "Batch 26/32, Loss: 0.0014\n",
      "Batch 27/32, Loss: 0.0016\n",
      "Batch 28/32, Loss: 0.0015\n",
      "Batch 29/32, Loss: 0.0014\n",
      "Batch 30/32, Loss: 0.0015\n",
      "Batch 31/32, Loss: 0.0017\n",
      "Batch 32/32, Loss: 0.0012\n",
      "Epoch [2/6] finished, Total Loss: 0.0586, Time: 352.93 seconds\n",
      "Layer: encoder1.0.weight, Grad Norm: 0.0004\n",
      "Layer: encoder1.0.bias, Grad Norm: 0.0002\n",
      "Layer: encoder1.2.weight, Grad Norm: 0.0001\n",
      "Layer: encoder1.2.bias, Grad Norm: 0.0001\n",
      "Layer: encoder1.4.weight, Grad Norm: 0.0002\n",
      "Layer: encoder1.4.bias, Grad Norm: 0.0000\n",
      "Layer: encoder1.6.weight, Grad Norm: 0.0001\n",
      "Layer: encoder1.6.bias, Grad Norm: 0.0001\n",
      "Layer: encoder2.0.weight, Grad Norm: 0.0008\n",
      "Layer: encoder2.0.bias, Grad Norm: 0.0003\n",
      "Layer: encoder2.2.weight, Grad Norm: 0.0001\n",
      "Layer: encoder2.2.bias, Grad Norm: 0.0001\n",
      "Layer: encoder2.4.weight, Grad Norm: 0.0003\n",
      "Layer: encoder2.4.bias, Grad Norm: 0.0000\n",
      "Layer: encoder2.6.weight, Grad Norm: 0.0001\n",
      "Layer: encoder2.6.bias, Grad Norm: 0.0001\n",
      "Layer: encoder3.0.weight, Grad Norm: 0.0011\n",
      "Layer: encoder3.0.bias, Grad Norm: 0.0002\n",
      "Layer: encoder3.2.weight, Grad Norm: 0.0002\n",
      "Layer: encoder3.2.bias, Grad Norm: 0.0004\n",
      "Layer: encoder3.4.weight, Grad Norm: 0.0006\n",
      "Layer: encoder3.4.bias, Grad Norm: 0.0000\n",
      "Layer: encoder3.6.weight, Grad Norm: 0.0002\n",
      "Layer: encoder3.6.bias, Grad Norm: 0.0001\n",
      "Layer: encoder4.0.weight, Grad Norm: 0.0011\n",
      "Layer: encoder4.0.bias, Grad Norm: 0.0002\n",
      "Layer: encoder4.2.weight, Grad Norm: 0.0003\n",
      "Layer: encoder4.2.bias, Grad Norm: 0.0008\n",
      "Layer: encoder4.4.weight, Grad Norm: 0.0006\n",
      "Layer: encoder4.4.bias, Grad Norm: 0.0000\n",
      "Layer: encoder4.6.weight, Grad Norm: 0.0003\n",
      "Layer: encoder4.6.bias, Grad Norm: 0.0001\n",
      "Layer: decoder.0.weight, Grad Norm: 0.0007\n",
      "Layer: decoder.0.bias, Grad Norm: 0.0000\n",
      "Layer: decoder.2.weight, Grad Norm: 0.0002\n",
      "Layer: decoder.2.bias, Grad Norm: 0.0001\n",
      "Layer: decoder.3.weight, Grad Norm: 0.0004\n",
      "Layer: decoder.3.bias, Grad Norm: 0.0000\n",
      "Batch 1/32, Loss: 0.0014\n",
      "Batch 2/32, Loss: 0.0012\n",
      "Batch 3/32, Loss: 0.0013\n",
      "Batch 4/32, Loss: 0.0014\n",
      "Batch 5/32, Loss: 0.0012\n",
      "Batch 6/32, Loss: 0.0013\n",
      "Batch 7/32, Loss: 0.0012\n",
      "Batch 8/32, Loss: 0.0012\n",
      "Batch 9/32, Loss: 0.0010\n",
      "Batch 10/32, Loss: 0.0011\n",
      "Batch 11/32, Loss: 0.0013\n",
      "Batch 12/32, Loss: 0.0011\n",
      "Batch 13/32, Loss: 0.0011\n",
      "Batch 14/32, Loss: 0.0014\n",
      "Batch 15/32, Loss: 0.0011\n",
      "Batch 16/32, Loss: 0.0012\n",
      "Batch 17/32, Loss: 0.0012\n",
      "Batch 18/32, Loss: 0.0015\n",
      "Batch 19/32, Loss: 0.0011\n",
      "Batch 20/32, Loss: 0.0012\n",
      "Batch 21/32, Loss: 0.0011\n",
      "Batch 22/32, Loss: 0.0012\n",
      "Batch 23/32, Loss: 0.0011\n",
      "Batch 24/32, Loss: 0.0011\n",
      "Batch 25/32, Loss: 0.0011\n",
      "Batch 26/32, Loss: 0.0011\n",
      "Batch 27/32, Loss: 0.0011\n",
      "Batch 28/32, Loss: 0.0010\n",
      "Batch 29/32, Loss: 0.0010\n",
      "Batch 30/32, Loss: 0.0010\n",
      "Batch 31/32, Loss: 0.0010\n",
      "Batch 32/32, Loss: 0.0018\n",
      "Epoch [3/6] finished, Total Loss: 0.0379, Time: 366.33 seconds\n",
      "Layer: encoder1.0.weight, Grad Norm: 0.0007\n",
      "Layer: encoder1.0.bias, Grad Norm: 0.0008\n",
      "Layer: encoder1.2.weight, Grad Norm: 0.0002\n",
      "Layer: encoder1.2.bias, Grad Norm: 0.0001\n",
      "Layer: encoder1.4.weight, Grad Norm: 0.0003\n",
      "Layer: encoder1.4.bias, Grad Norm: 0.0000\n",
      "Layer: encoder1.6.weight, Grad Norm: 0.0002\n",
      "Layer: encoder1.6.bias, Grad Norm: 0.0004\n",
      "Layer: encoder2.0.weight, Grad Norm: 0.0013\n",
      "Layer: encoder2.0.bias, Grad Norm: 0.0021\n",
      "Layer: encoder2.2.weight, Grad Norm: 0.0002\n",
      "Layer: encoder2.2.bias, Grad Norm: 0.0003\n",
      "Layer: encoder2.4.weight, Grad Norm: 0.0008\n",
      "Layer: encoder2.4.bias, Grad Norm: 0.0000\n",
      "Layer: encoder2.6.weight, Grad Norm: 0.0003\n",
      "Layer: encoder2.6.bias, Grad Norm: 0.0003\n",
      "Layer: encoder3.0.weight, Grad Norm: 0.0027\n",
      "Layer: encoder3.0.bias, Grad Norm: 0.0029\n",
      "Layer: encoder3.2.weight, Grad Norm: 0.0010\n",
      "Layer: encoder3.2.bias, Grad Norm: 0.0006\n",
      "Layer: encoder3.4.weight, Grad Norm: 0.0015\n",
      "Layer: encoder3.4.bias, Grad Norm: 0.0000\n",
      "Layer: encoder3.6.weight, Grad Norm: 0.0005\n",
      "Layer: encoder3.6.bias, Grad Norm: 0.0004\n",
      "Layer: encoder4.0.weight, Grad Norm: 0.0023\n",
      "Layer: encoder4.0.bias, Grad Norm: 0.0006\n",
      "Layer: encoder4.2.weight, Grad Norm: 0.0015\n",
      "Layer: encoder4.2.bias, Grad Norm: 0.0015\n",
      "Layer: encoder4.4.weight, Grad Norm: 0.0016\n",
      "Layer: encoder4.4.bias, Grad Norm: 0.0000\n",
      "Layer: encoder4.6.weight, Grad Norm: 0.0010\n",
      "Layer: encoder4.6.bias, Grad Norm: 0.0006\n",
      "Layer: decoder.0.weight, Grad Norm: 0.0016\n",
      "Layer: decoder.0.bias, Grad Norm: 0.0001\n",
      "Layer: decoder.2.weight, Grad Norm: 0.0009\n",
      "Layer: decoder.2.bias, Grad Norm: 0.0012\n",
      "Layer: decoder.3.weight, Grad Norm: 0.0011\n",
      "Layer: decoder.3.bias, Grad Norm: 0.0004\n",
      "Batch 1/32, Loss: 0.0010\n",
      "Batch 2/32, Loss: 0.0010\n",
      "Batch 3/32, Loss: 0.0009\n",
      "Batch 4/32, Loss: 0.0010\n",
      "Batch 5/32, Loss: 0.0011\n",
      "Batch 6/32, Loss: 0.0010\n",
      "Batch 7/32, Loss: 0.0008\n",
      "Batch 8/32, Loss: 0.0010\n",
      "Batch 9/32, Loss: 0.0010\n",
      "Batch 10/32, Loss: 0.0009\n",
      "Batch 11/32, Loss: 0.0010\n",
      "Batch 12/32, Loss: 0.0010\n",
      "Batch 13/32, Loss: 0.0009\n",
      "Batch 14/32, Loss: 0.0010\n",
      "Batch 15/32, Loss: 0.0008\n",
      "Batch 16/32, Loss: 0.0008\n",
      "Batch 17/32, Loss: 0.0007\n",
      "Batch 18/32, Loss: 0.0009\n",
      "Batch 19/32, Loss: 0.0011\n",
      "Batch 20/32, Loss: 0.0010\n",
      "Batch 21/32, Loss: 0.0008\n",
      "Batch 22/32, Loss: 0.0007\n",
      "Batch 23/32, Loss: 0.0009\n",
      "Batch 24/32, Loss: 0.0008\n",
      "Batch 25/32, Loss: 0.0008\n",
      "Batch 26/32, Loss: 0.0008\n",
      "Batch 27/32, Loss: 0.0010\n",
      "Batch 28/32, Loss: 0.0007\n",
      "Batch 29/32, Loss: 0.0008\n",
      "Batch 30/32, Loss: 0.0007\n",
      "Batch 31/32, Loss: 0.0008\n",
      "Batch 32/32, Loss: 0.0017\n",
      "Epoch [4/6] finished, Total Loss: 0.0293, Time: 348.80 seconds\n",
      "Layer: encoder1.0.weight, Grad Norm: 0.0012\n",
      "Layer: encoder1.0.bias, Grad Norm: 0.0018\n",
      "Layer: encoder1.2.weight, Grad Norm: 0.0001\n",
      "Layer: encoder1.2.bias, Grad Norm: 0.0001\n",
      "Layer: encoder1.4.weight, Grad Norm: 0.0005\n",
      "Layer: encoder1.4.bias, Grad Norm: 0.0000\n",
      "Layer: encoder1.6.weight, Grad Norm: 0.0002\n",
      "Layer: encoder1.6.bias, Grad Norm: 0.0001\n",
      "Layer: encoder2.0.weight, Grad Norm: 0.0124\n",
      "Layer: encoder2.0.bias, Grad Norm: 0.0083\n",
      "Layer: encoder2.2.weight, Grad Norm: 0.0015\n",
      "Layer: encoder2.2.bias, Grad Norm: 0.0008\n",
      "Layer: encoder2.4.weight, Grad Norm: 0.0049\n",
      "Layer: encoder2.4.bias, Grad Norm: 0.0001\n",
      "Layer: encoder2.6.weight, Grad Norm: 0.0009\n",
      "Layer: encoder2.6.bias, Grad Norm: 0.0001\n",
      "Layer: encoder3.0.weight, Grad Norm: 0.0060\n",
      "Layer: encoder3.0.bias, Grad Norm: 0.0009\n",
      "Layer: encoder3.2.weight, Grad Norm: 0.0009\n",
      "Layer: encoder3.2.bias, Grad Norm: 0.0004\n",
      "Layer: encoder3.4.weight, Grad Norm: 0.0020\n",
      "Layer: encoder3.4.bias, Grad Norm: 0.0000\n",
      "Layer: encoder3.6.weight, Grad Norm: 0.0006\n",
      "Layer: encoder3.6.bias, Grad Norm: 0.0001\n",
      "Layer: encoder4.0.weight, Grad Norm: 0.0061\n",
      "Layer: encoder4.0.bias, Grad Norm: 0.0005\n",
      "Layer: encoder4.2.weight, Grad Norm: 0.0009\n",
      "Layer: encoder4.2.bias, Grad Norm: 0.0010\n",
      "Layer: encoder4.4.weight, Grad Norm: 0.0021\n",
      "Layer: encoder4.4.bias, Grad Norm: 0.0000\n",
      "Layer: encoder4.6.weight, Grad Norm: 0.0007\n",
      "Layer: encoder4.6.bias, Grad Norm: 0.0001\n",
      "Layer: decoder.0.weight, Grad Norm: 0.0022\n",
      "Layer: decoder.0.bias, Grad Norm: 0.0001\n",
      "Layer: decoder.2.weight, Grad Norm: 0.0007\n",
      "Layer: decoder.2.bias, Grad Norm: 0.0005\n",
      "Layer: decoder.3.weight, Grad Norm: 0.0014\n",
      "Layer: decoder.3.bias, Grad Norm: 0.0001\n",
      "Batch 1/32, Loss: 0.0007\n",
      "Batch 2/32, Loss: 0.0007\n",
      "Batch 3/32, Loss: 0.0011\n",
      "Batch 4/32, Loss: 0.0010\n",
      "Batch 5/32, Loss: 0.0007\n",
      "Batch 6/32, Loss: 0.0009\n",
      "Batch 7/32, Loss: 0.0008\n",
      "Batch 8/32, Loss: 0.0007\n",
      "Batch 9/32, Loss: 0.0008\n",
      "Batch 10/32, Loss: 0.0012\n",
      "Batch 11/32, Loss: 0.0008\n",
      "Batch 12/32, Loss: 0.0007\n",
      "Batch 13/32, Loss: 0.0008\n",
      "Batch 14/32, Loss: 0.0007\n",
      "Batch 15/32, Loss: 0.0013\n",
      "Batch 16/32, Loss: 0.0006\n",
      "Batch 17/32, Loss: 0.0008\n",
      "Batch 18/32, Loss: 0.0008\n",
      "Batch 19/32, Loss: 0.0010\n",
      "Batch 20/32, Loss: 0.0007\n",
      "Batch 21/32, Loss: 0.0007\n",
      "Batch 22/32, Loss: 0.0006\n",
      "Batch 23/32, Loss: 0.0006\n",
      "Batch 24/32, Loss: 0.0008\n",
      "Batch 25/32, Loss: 0.0007\n",
      "Batch 26/32, Loss: 0.0008\n",
      "Batch 27/32, Loss: 0.0007\n",
      "Batch 28/32, Loss: 0.0006\n",
      "Batch 29/32, Loss: 0.0009\n",
      "Batch 30/32, Loss: 0.0005\n",
      "Batch 31/32, Loss: 0.0006\n",
      "Batch 32/32, Loss: 0.0009\n",
      "Epoch [5/6] finished, Total Loss: 0.0251, Time: 379.27 seconds\n",
      "Layer: encoder1.0.weight, Grad Norm: 0.0004\n",
      "Layer: encoder1.0.bias, Grad Norm: 0.0003\n",
      "Layer: encoder1.2.weight, Grad Norm: 0.0001\n",
      "Layer: encoder1.2.bias, Grad Norm: 0.0001\n",
      "Layer: encoder1.4.weight, Grad Norm: 0.0003\n",
      "Layer: encoder1.4.bias, Grad Norm: 0.0000\n",
      "Layer: encoder1.6.weight, Grad Norm: 0.0001\n",
      "Layer: encoder1.6.bias, Grad Norm: 0.0001\n",
      "Layer: encoder2.0.weight, Grad Norm: 0.0007\n",
      "Layer: encoder2.0.bias, Grad Norm: 0.0005\n",
      "Layer: encoder2.2.weight, Grad Norm: 0.0001\n",
      "Layer: encoder2.2.bias, Grad Norm: 0.0001\n",
      "Layer: encoder2.4.weight, Grad Norm: 0.0004\n",
      "Layer: encoder2.4.bias, Grad Norm: 0.0000\n",
      "Layer: encoder2.6.weight, Grad Norm: 0.0001\n",
      "Layer: encoder2.6.bias, Grad Norm: 0.0001\n",
      "Layer: encoder3.0.weight, Grad Norm: 0.0013\n",
      "Layer: encoder3.0.bias, Grad Norm: 0.0004\n",
      "Layer: encoder3.2.weight, Grad Norm: 0.0003\n",
      "Layer: encoder3.2.bias, Grad Norm: 0.0003\n",
      "Layer: encoder3.4.weight, Grad Norm: 0.0007\n",
      "Layer: encoder3.4.bias, Grad Norm: 0.0000\n",
      "Layer: encoder3.6.weight, Grad Norm: 0.0003\n",
      "Layer: encoder3.6.bias, Grad Norm: 0.0001\n",
      "Layer: encoder4.0.weight, Grad Norm: 0.0022\n",
      "Layer: encoder4.0.bias, Grad Norm: 0.0004\n",
      "Layer: encoder4.2.weight, Grad Norm: 0.0007\n",
      "Layer: encoder4.2.bias, Grad Norm: 0.0011\n",
      "Layer: encoder4.4.weight, Grad Norm: 0.0010\n",
      "Layer: encoder4.4.bias, Grad Norm: 0.0000\n",
      "Layer: encoder4.6.weight, Grad Norm: 0.0006\n",
      "Layer: encoder4.6.bias, Grad Norm: 0.0001\n",
      "Layer: decoder.0.weight, Grad Norm: 0.0009\n",
      "Layer: decoder.0.bias, Grad Norm: 0.0000\n",
      "Layer: decoder.2.weight, Grad Norm: 0.0002\n",
      "Layer: decoder.2.bias, Grad Norm: 0.0002\n",
      "Layer: decoder.3.weight, Grad Norm: 0.0004\n",
      "Layer: decoder.3.bias, Grad Norm: 0.0001\n",
      "Batch 1/32, Loss: 0.0006\n",
      "Batch 2/32, Loss: 0.0006\n",
      "Batch 3/32, Loss: 0.0008\n",
      "Batch 4/32, Loss: 0.0007\n",
      "Batch 5/32, Loss: 0.0005\n",
      "Batch 6/32, Loss: 0.0005\n",
      "Batch 7/32, Loss: 0.0005\n",
      "Batch 8/32, Loss: 0.0006\n",
      "Batch 9/32, Loss: 0.0007\n",
      "Batch 10/32, Loss: 0.0006\n",
      "Batch 11/32, Loss: 0.0005\n",
      "Batch 12/32, Loss: 0.0006\n",
      "Batch 13/32, Loss: 0.0007\n",
      "Batch 14/32, Loss: 0.0005\n",
      "Batch 15/32, Loss: 0.0007\n",
      "Batch 16/32, Loss: 0.0006\n",
      "Batch 17/32, Loss: 0.0005\n",
      "Batch 18/32, Loss: 0.0006\n",
      "Batch 19/32, Loss: 0.0005\n",
      "Batch 20/32, Loss: 0.0004\n",
      "Batch 21/32, Loss: 0.0005\n",
      "Batch 22/32, Loss: 0.0005\n",
      "Batch 23/32, Loss: 0.0005\n",
      "Batch 24/32, Loss: 0.0007\n",
      "Batch 25/32, Loss: 0.0005\n",
      "Batch 26/32, Loss: 0.0007\n",
      "Batch 27/32, Loss: 0.0007\n",
      "Batch 28/32, Loss: 0.0004\n",
      "Batch 29/32, Loss: 0.0005\n",
      "Batch 30/32, Loss: 0.0005\n",
      "Batch 31/32, Loss: 0.0005\n",
      "Batch 32/32, Loss: 0.0006\n",
      "Epoch [6/6] finished, Total Loss: 0.0183, Time: 369.93 seconds\n",
      "Layer: encoder1.0.weight, Grad Norm: 0.0003\n",
      "Layer: encoder1.0.bias, Grad Norm: 0.0000\n",
      "Layer: encoder1.2.weight, Grad Norm: 0.0000\n",
      "Layer: encoder1.2.bias, Grad Norm: 0.0000\n",
      "Layer: encoder1.4.weight, Grad Norm: 0.0002\n",
      "Layer: encoder1.4.bias, Grad Norm: 0.0000\n",
      "Layer: encoder1.6.weight, Grad Norm: 0.0001\n",
      "Layer: encoder1.6.bias, Grad Norm: 0.0001\n",
      "Layer: encoder2.0.weight, Grad Norm: 0.0014\n",
      "Layer: encoder2.0.bias, Grad Norm: 0.0004\n",
      "Layer: encoder2.2.weight, Grad Norm: 0.0001\n",
      "Layer: encoder2.2.bias, Grad Norm: 0.0002\n",
      "Layer: encoder2.4.weight, Grad Norm: 0.0003\n",
      "Layer: encoder2.4.bias, Grad Norm: 0.0000\n",
      "Layer: encoder2.6.weight, Grad Norm: 0.0001\n",
      "Layer: encoder2.6.bias, Grad Norm: 0.0001\n",
      "Layer: encoder3.0.weight, Grad Norm: 0.0035\n",
      "Layer: encoder3.0.bias, Grad Norm: 0.0006\n",
      "Layer: encoder3.2.weight, Grad Norm: 0.0002\n",
      "Layer: encoder3.2.bias, Grad Norm: 0.0002\n",
      "Layer: encoder3.4.weight, Grad Norm: 0.0006\n",
      "Layer: encoder3.4.bias, Grad Norm: 0.0000\n",
      "Layer: encoder3.6.weight, Grad Norm: 0.0001\n",
      "Layer: encoder3.6.bias, Grad Norm: 0.0001\n",
      "Layer: encoder4.0.weight, Grad Norm: 0.0027\n",
      "Layer: encoder4.0.bias, Grad Norm: 0.0002\n",
      "Layer: encoder4.2.weight, Grad Norm: 0.0004\n",
      "Layer: encoder4.2.bias, Grad Norm: 0.0012\n",
      "Layer: encoder4.4.weight, Grad Norm: 0.0007\n",
      "Layer: encoder4.4.bias, Grad Norm: 0.0000\n",
      "Layer: encoder4.6.weight, Grad Norm: 0.0002\n",
      "Layer: encoder4.6.bias, Grad Norm: 0.0001\n",
      "Layer: decoder.0.weight, Grad Norm: 0.0007\n",
      "Layer: decoder.0.bias, Grad Norm: 0.0000\n",
      "Layer: decoder.2.weight, Grad Norm: 0.0001\n",
      "Layer: decoder.2.bias, Grad Norm: 0.0001\n",
      "Layer: decoder.3.weight, Grad Norm: 0.0003\n",
      "Layer: decoder.3.bias, Grad Norm: 0.0000\n"
     ]
    }
   ],
   "source": [
    "# for i in range(20):\n",
    "# 开始训练卷积神经网络\n",
    "CQNet.train_supervised_model(conv_net, ans_tensor, train_num = 6, labels= labels_tensor, batch_size=8, learning_rate=0.005)\n",
    "# 保存模型参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 保存模型参数\n",
    "torch.save(conv_net.state_dict(), \"./model/SuperDeep.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用训练后的模型进行预测\n",
    "conv_net.eval()\n",
    "with torch.no_grad():\n",
    "    predictions = conv_net(ans_tensor)\n",
    "\n",
    "# 交互式显示切片和预测结果\n",
    "CQNet.interactive_plot(ans_tensor[0:1], predictions[0:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ans_tensor[0:10].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchviz import make_dot\n",
    "\n",
    "# 创建模型实例\n",
    "conv_net = ConvNet()\n",
    "\n",
    "# 生成一个随机输入数据\n",
    "x = torch.randn(1, 1, 1200, 1024)  # 根据您的输入尺寸进行调整\n",
    "\n",
    "# 前向传播\n",
    "y = conv_net(x)\n",
    "\n",
    "# 可视化计算图\n",
    "dot = make_dot(y, params=dict(conv_net.named_parameters()))\n",
    "dot.render(\"conv_net_architecture\", format=\"png\")  # 生成 PNG 文件"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
